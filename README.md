# Proyecto de Procesamiento de Videos con YOLOv8

## DescripciÃ³n

Este proyecto implementa un sistema completo de detecciÃ³n y anÃ¡lisis de objetos en imÃ¡genes y videos usando YOLOv8. Incluye funcionalidades avanzadas como tracking de objetos, anÃ¡lisis de zonas de interÃ©s, y un sistema de confirmaciÃ³n mejorado para reducir falsos negativos.

## CaracterÃ­sticas Principales

### ğŸ¯ **DetecciÃ³n Mejorada**
- **Sistema de confirmaciÃ³n**: Solo asigna IDs a objetos que aparecen en 5+ frames consecutivos
- **Tracking persistente**: Mantiene identidad de objetos entre frames
- **Umbral de confianza configurable**: Por defecto 0.25 para mÃ¡xima sensibilidad
- **Filtrado inteligente**: Reduce falsos positivos y falsos negativos

### ğŸ“¹ **Funcionalidades de Video**
- **DetecciÃ³n bÃ¡sica**: IdentificaciÃ³n de objetos en tiempo real
- **Tracking avanzado**: Seguimiento de objetos con IDs Ãºnicos y trayectorias
- **AnÃ¡lisis de zonas**: DetecciÃ³n de entrada en Ã¡reas especÃ­ficas y cruce de lÃ­neas
- **EstadÃ­sticas en tiempo real**: Contadores de frames y detecciones

### ğŸ–¼ï¸ **Procesamiento de ImÃ¡genes**
- **DetecciÃ³n de objetos**: IdentificaciÃ³n con bounding boxes y etiquetas
- **Colores dinÃ¡micos**: Verde para alta confianza, naranja para baja
- **Fondo negro en etiquetas**: Mejor visibilidad del texto

## InstalaciÃ³n

```bash
# Clonar el repositorio
git clone <repository-url>
cd videos_yolo

# Instalar dependencias
pip install -r requirements.txt
```

## Uso

### DetecciÃ³n en ImÃ¡genes

```bash
python src/main.py \
    --image "data/images/person.jpg" \
    --model "models/yolov8x.pt" \
    --conf-threshold 0.25 \
    --show
```

### Procesamiento de Video

```bash
python src/main.py video \
    --video-path "data/videos/people.mp4" \
    --model-path "models/yolov8x.pt" \
    --conf-threshold 0.25 \
    --show
```

### Tracking de Objetos

```bash
python src/main.py track \
    --video-path "data/videos/people.mp4" \
    --model-path "models/yolov8x.pt" \
    --show
```

### AnÃ¡lisis con Zonas de InterÃ©s

```bash
python src/main.py analyze \
    --video-path "data/videos/people.mp4" \
    --model-path "models/yolov8x.pt" \
    --zones-json "configs/zonas.json" \
    --conf-threshold 0.25 \
    --show
```

## ParÃ¡metros Principales

- `--conf-threshold`: Umbral de confianza (0.0-1.0, por defecto 0.25)
- `--classes`: Lista de clases a detectar (ej: "person,car,dog")
- `--show`: Mostrar visualizaciÃ³n en tiempo real
- `--output`: Ruta de salida personalizada

## Modelos Recomendados

Para lograr la **mÃ¡xima detecciÃ³n** de personas:

1. **YOLOv8x** (`yolov8x.pt`) - MÃ¡xima precisiÃ³n
2. **YOLOv8l** (`yolov8l.pt`) - Alta precisiÃ³n
3. **YOLOv8m** (`yolov8m.pt`) - Buena precisiÃ³n

> **Nota**: Los modelos mÃ¡s grandes requieren GPU para tiempo real.

## Mejoras Implementadas

### ğŸ”§ **Sistema de ConfirmaciÃ³n**
- Filtra detecciones breves (menos de 5 frames)
- Asigna IDs estables y secuenciales
- Reduce falsos positivos automÃ¡ticamente

### ğŸ¨ **VisualizaciÃ³n Mejorada**
- Colores basados en confianza
- Trayectorias de movimiento
- Etiquetas con fondo negro
- EstadÃ­sticas en tiempo real

### âš¡ **Optimizaciones de Rendimiento**
- Tracking persistente habilitado
- Umbral de confianza configurable
- Procesamiento eficiente de frames

## Estructura del Proyecto

```
videos_yolo/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py              # CLI principal
â”‚   â”œâ”€â”€ detect.py            # DetecciÃ³n en imÃ¡genes
â”‚   â”œâ”€â”€ tracking.py          # Tracking de objetos
â”‚   â”œâ”€â”€ video_processing.py  # Procesamiento de video
â”‚   â”œâ”€â”€ video_analysis.py    # AnÃ¡lisis avanzado
â”‚   â””â”€â”€ utils/               # Utilidades
â”œâ”€â”€ models/                  # Modelos YOLO
â”œâ”€â”€ configs/                 # Configuraciones
â”œâ”€â”€ data/                    # Datos de entrada
â””â”€â”€ outputs/                 # Resultados
```

## ContribuciÃ³n

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

## Agradecimientos

- [Ultralytics](https://github.com/ultralytics/ultralytics) por YOLOv8
- [OpenCV](https://opencv.org/) por el procesamiento de video
- [Typer](https://typer.tiangolo.com/) por la interfaz CLI